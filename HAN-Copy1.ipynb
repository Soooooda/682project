{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = \"cpu\"\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (6,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path = \"dataset/\"\n",
    "df = pd.read_csv(path+\"USvideos.csv\")\n",
    "df = df.assign(country=\"US\")\n",
    "# df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')  \n",
    "# df.trending_date = df.trending_date.dt.date   \n",
    "# df['publish_time'] = pd.to_datetime(df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "# df=df.assign(publish_date=df['publish_time'].dt.date)\n",
    "# df['publish_time'] = df['publish_time'].dt.time\n",
    "\n",
    "# ###导入category名称###\n",
    "# df=df.assign(cat_name='a')\n",
    "# id_to_category = {}\n",
    "# file=path+'US_category_id.json'\n",
    "# with open(file, 'r') as f:\n",
    "#     data=json.load(f)\n",
    "#     for category in data['items']:\n",
    "#         id_to_category[category['id']] = category['snippet']['title']\n",
    "# print(id_to_category)\n",
    "# ###实际上每个国家的category id-name 字典是一样的\n",
    "# df['category_id'] = df['category_id'].astype(str)\n",
    "# df.insert(4, 'category', df['category_id'].map(id_to_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>views</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO 鈻?\\n\\nSUBSCRIBE 鈻?http...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  views Unnamed: 2  \\\n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...      1        NaN   \n",
       "1  One year after the presidential election, John...      2        NaN   \n",
       "2  WATCH MY PREVIOUS VIDEO 鈻?\\n\\nSUBSCRIBE 鈻?http...      2        NaN   \n",
       "3  Today we find out if Link is a Nickelback amat...      0        NaN   \n",
       "4  I know it's been a while since we did this sho...      1        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  Unnamed: 7 Unnamed: 8  \\\n",
       "0        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "2        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "3        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "4        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "\n",
       "  Unnamed: 9  ... Unnamed: 18 Unnamed: 19 Unnamed: 20 Unnamed: 21 Unnamed: 22  \\\n",
       "0        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "1        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "2        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "3        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "4        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 23 Unnamed: 24 Unnamed: 25  Unnamed: 26  country  \n",
       "0         NaN         NaN         NaN          NaN       US  \n",
       "1         NaN         NaN         NaN          NaN       US  \n",
       "2         NaN         NaN         NaN          NaN       US  \n",
       "3         NaN         NaN         NaN          NaN       US  \n",
       "4         NaN         NaN         NaN          NaN       US  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## mark the columns which contains text for classification and target class\n",
    "col_text = 'description'\n",
    "col_target = 'views'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_arr = np.sort(df[col_target].unique()).tolist()\n",
    "classes = len(cls_arr)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide dataset in 80% train 10% validation 10% test as done in the paper\n",
    "length = df.shape[0]\n",
    "train_len = int(0.8*length)\n",
    "val_len = int(0.1*length)\n",
    "\n",
    "train = df[:train_len]\n",
    "val = df[train_len:train_len+val_len]\n",
    "test = df[train_len+val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string, max_seq_len):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = str(string)\n",
    "    string = BeautifulSoup(string, \"lxml\").text\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\\"\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\\"s\", \" \\\"s\", string)\n",
    "    string = re.sub(r\"\\\"ve\", \" \\\"ve\", string)\n",
    "    string = re.sub(r\"n\\\"t\", \" n\\\"t\", string)\n",
    "    string = re.sub(r\"\\\"re\", \" \\\"re\", string)\n",
    "    string = re.sub(r\"\\\"d\", \" \\\"d\", string)\n",
    "    string = re.sub(r\"\\\"ll\", \" \\\"ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    s =string.strip().lower().split(\" \")\n",
    "    if len(s) > max_seq_len:\n",
    "        return s[0:max_seq_len] \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a 3D list of format paragraph[sentence[word]]\n",
    "def create3DList(df,col, max_sent_len,max_seq_len):\n",
    "    x=[]\n",
    "    for docs in df[col].as_matrix():\n",
    "        x1=[]\n",
    "        idx = 0\n",
    "        docs = str(docs)\n",
    "        for seq in \"|||\".join(re.split(\"[.?!]\", docs)).split(\"|||\"):\n",
    "            x1.append(clean_str(seq,max_sent_len))\n",
    "            if(idx>=max_seq_len-1):\n",
    "                break\n",
    "            idx= idx+1\n",
    "        x.append(x1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix the maximum length of sentences in a paragraph and words in a sentence\n",
    "max_sent_len = 12\n",
    "max_seq_len = 25\n",
    "# print(df[col].as_matrix()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://www\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://youtu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://www\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://goo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://facebook\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://twitter\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://ctt\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://twitter\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://instagram\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://snpcht\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://facebook\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://smu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://esteelalonde\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://po\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://shop\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://GinWigmore\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://smarturl\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://store\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://hevesh5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://tiltify\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://youtube\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://theguardian\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://is\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://loudwire\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://sub2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://snapchat\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://Teespring\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://GhostAndStars\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://open\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://itunes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://soundcloud\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://olenkalovers\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://olenkalovers\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://spoti\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://apple\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://votetheprocess\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://zaydewolf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://dk4l\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://plus\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://hondaloves\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://snapchat\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://shopcaseyneistat\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://republic\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://readyplayeronemovie\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://amzn\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://github\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://ShopLoganPaul\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://shots\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://shop\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://discuss\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://represent\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://carlyanderin\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://shots\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://bit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://crmbs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://tickets\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://fb\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://pointlessblogtv\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://kyoto-kitcho\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://instagram\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://t\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://patreon\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://omny\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://people\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://guardian\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://turbotax\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://morphebrushes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://pastebin\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://Squarespace\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://lifeformed\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://hackaday\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://billwurtz\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://crowdmade\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://goo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://damonandjo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://kinded\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://annaed\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://store\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://librivox\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://thegame730am\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://youtu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://shortyawards\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://time\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://Spoti\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://YouTube\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://soundcloud\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://reddit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://https://www\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://solidgoldaquatics\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://xgam\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bachelorinsider\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://pinterest\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://go90\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://au\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://like\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://evanedinger\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://navalny\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://2018\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://youtube\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://eepurl\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://intuit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://apple\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://tapastic\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://build-its-inprogress\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://crowdmade\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://tidd\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bramfam\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://markiplier\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://freshmanxxlmag\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://nyti\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://poobear\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://discordapp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://petitecosmetics\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://vote\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://vevo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bhcosmetics\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://woodgears\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://ptxofficial\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://AlisonWonderland\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://twicejapan\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://teamedge\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://moreclutterfree\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://warehouse\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://rugwear\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://m\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://beaklondike\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://skl\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://DeFrancoElite\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://BetterHelp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://PostDeFranco\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://dollarshaveclub\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://hellohonne\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://tour\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://peppermint\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://remyny\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 32580\n",
      "x_val: 4072\n",
      "x_test: 4074\n"
     ]
    }
   ],
   "source": [
    "## divides review in sentences and sentences into word creating a 3DList\n",
    "x_train = create3DList(train,col_text, max_sent_len,max_seq_len)\n",
    "x_val = create3DList(val, col_text, max_sent_len,max_seq_len)\n",
    "x_test = create3DList(test, col_text, max_sent_len,max_seq_len)\n",
    "print(\"x_train: {}\".format(len(x_train)))\n",
    "print(\"x_val: {}\".format(len(x_val)))\n",
    "print(\"x_test: {}\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english') + list(string.punctuation)\n",
    "stemmer = SnowballStemmer('english')\n",
    "x_train_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_train]\n",
    "x_test_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_test]\n",
    "x_val_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_val]\n",
    "\n",
    "## calculate frequency of words\n",
    "from collections import defaultdict\n",
    "frequency1 = defaultdict(int)\n",
    "for texts in x_train_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_test_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_val_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "            \n",
    "## remove  words with frequency less than 5.\n",
    "x_train_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_train_texts]\n",
    "\n",
    "x_test_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_test_texts]\n",
    "x_val_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(more_itertools.collapse(x_train_texts[:] + x_test_texts[:] + x_val_texts[:],levels=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(texts,size=200, min_count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save(\"dictonary_youtube\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert 3D text list to 3D list of index \n",
    "x_train_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weights = torch.FloatTensor(word2vec.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2vec.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[col_target].tolist()\n",
    "y_test = test[col_target].tolist()\n",
    "y_val = val[col_target].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the the multiple attention with word vectors.\n",
    "def attention_mul(rnn_outputs, att_weights):\n",
    "    attn_vectors = None\n",
    "    for i in range(rnn_outputs.size(0)):\n",
    "        h_i = rnn_outputs[i]\n",
    "        a_i = att_weights[i]\n",
    "        h_i = a_i * h_i\n",
    "        h_i = h_i.unsqueeze(0)\n",
    "        if(attn_vectors is None):\n",
    "            attn_vectors = h_i\n",
    "        else:\n",
    "            attn_vectors = torch.cat((attn_vectors,h_i),0)\n",
    "    return torch.sum(attn_vectors, 0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The word RNN model for generating a sentence vector\n",
    "class WordRNN(nn.Module):\n",
    "    def __init__(self, vocab_size,embedsize, batch_size, hid_size):\n",
    "        super(WordRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        ## Word Encoder\n",
    "        self.embed = nn.Embedding(vocab_size, embedsize)\n",
    "        self.wordRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Word Attention\n",
    "        self.wordattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "    def forward(self,inp, hid_state):\n",
    "        emb_out  = self.embed(inp)\n",
    "\n",
    "        out_state, hid_state = self.wordRNN(emb_out, hid_state)\n",
    "\n",
    "        word_annotation = self.wordattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(word_annotation),dim=1)\n",
    "\n",
    "        sent = attention_mul(out_state,attn)\n",
    "        return sent, hid_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The HAN model\n",
    "class SentenceRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedsize, batch_size, hid_size,c):\n",
    "        super(SentenceRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        self.cls = c\n",
    "        self.wordRNN = WordRNN(vocab_size,embedsize, batch_size, hid_size)\n",
    "        ## Sentence Encoder\n",
    "        self.sentRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Sentence Attention\n",
    "        self.sentattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "        self.doc_linear = nn.Linear(2*hid_size, c)\n",
    "    \n",
    "    def forward(self,inp, hid_state_sent, hid_state_word):\n",
    "        s = None\n",
    "        ## Generating sentence vector through WordRNN\n",
    "        for i in range(len(inp[0])):\n",
    "            r = None\n",
    "            for j in range(len(inp)):\n",
    "                if(r is None):\n",
    "                    r = [inp[j][i]]\n",
    "                else:\n",
    "                    r.append(inp[j][i])\n",
    "            r1 = np.asarray([sub_list + [0] * (max_seq_len - len(sub_list)) for sub_list in r])\n",
    "            _s, state_word = self.wordRNN(torch.LongTensor(r1).view(-1,batch_size), hid_state_word)\n",
    "            if(s is None):\n",
    "                s = _s\n",
    "            else:\n",
    "                s = torch.cat((s,_s),0)\n",
    "\n",
    "                out_state, hid_state = self.sentRNN(s, hid_state_sent)\n",
    "        sent_annotation = self.sentattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(sent_annotation),dim=1)\n",
    "\n",
    "        doc = attention_mul(out_state,attn)\n",
    "        d = self.doc_linear(doc)\n",
    "        cls = F.log_softmax(d.view(-1,self.cls),dim=1)\n",
    "        return cls, hid_state\n",
    "    \n",
    "    def init_hidden_sent(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size))\n",
    "    \n",
    "    def init_hidden_word(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## converting list to tensor\n",
    "# # y_train[:10]\n",
    "y_train_tensor =  torch.from_numpy(np.array(y_train))#[torch.FloatTensor([cls_arr[label]]) for label in y_train]\n",
    "y_val_tensor =  torch.from_numpy(np.array(y_val))#[torch.FloatTensor([cls_arr[label]]) for label in y_val]\n",
    "y_test_tensor =  torch.from_numpy(np.array(y_test))#[torch.FloatTensor([cls_arr[label]]) for label in y_test]\n",
    "\n",
    "\n",
    "# ## converting list to tensor\n",
    "# y_train_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_train]\n",
    "# y_val_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_val]\n",
    "# y_test_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)])\n",
    "max_sent_len = max([len(sent) for sent in (x_train_vec + x_val_vec + x_test_vec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)]),90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(sent) for sent in (x_train_vec +x_val_vec + x_test_vec)]),90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding the input \n",
    "X_train_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_train_vec]\n",
    "X_val_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_val_vec]\n",
    "X_test_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_test_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(batch_size, review, targets, sent_attn_model, sent_optimizer, criterion):\n",
    "\n",
    "    state_word = sent_attn_model.init_hidden_word()\n",
    "    state_sent = sent_attn_model.init_hidden_sent()\n",
    "    sent_optimizer.zero_grad()\n",
    "            \n",
    "    y_pred, state_sent = sent_attn_model(review, state_sent, state_word)\n",
    "\n",
    "    loss = criterion(y_pred, torch.LongTensor(targets)) \n",
    "    \n",
    "    max_index = y_pred.max(dim = 1)[1]\n",
    "    correct = (max_index == torch.LongTensor(targets)).sum()\n",
    "    acc = float(correct)/batch_size\n",
    "\n",
    "    loss.backward()\n",
    "#     print(loss)\n",
    "    sent_optimizer.step()\n",
    "    \n",
    "    return loss.item(),acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 100\n",
    "embedsize = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_attn = SentenceRNN(vocab_size,embedsize,batch_size,hid_size,classes)\n",
    "sent_attn.wordRNN.embed.from_pretrained(weights)\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "\n",
    "sent_optimizer = torch.optim.SGD(sent_attn.parameters(), lr=learning_rate, momentum= momentum)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(x,y,batch_size):\n",
    "    k = random.sample(range(len(x)-1),batch_size)\n",
    "    x_batch=[]\n",
    "    y_batch=[]\n",
    "\n",
    "    for t in k:\n",
    "        x_batch.append(x[t])\n",
    "        y_batch.append(y[t])\n",
    "\n",
    "    return [x_batch,y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(batch_size, x_val,y_val,sent_attn_model):\n",
    "    acc = []\n",
    "    val_length = len(x_val)\n",
    "    for j in range(int(val_length/batch_size)):\n",
    "        x,y = gen_batch(x_val,y_val,batch_size)\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        \n",
    "        y_pred, state_sent = sent_attn_model(x, state_sent, state_word)\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(y)).sum()\n",
    "        acc.append(float(correct)/batch_size)\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_early_stopping(batch_size, x_train, y_train, x_val, y_val, sent_attn_model, \n",
    "                         sent_attn_optimiser, loss_criterion, num_epoch,\n",
    "                         print_loss_every = 50, code_test=True):\n",
    "    start = time.time()\n",
    "    loss_full = []\n",
    "    loss_epoch = []\n",
    "    acc_epoch = []\n",
    "    acc_full = []\n",
    "    val_acc = []\n",
    "    epoch_counter = 0\n",
    "    train_length = len(x_train)\n",
    "    for i in range(1, num_epoch + 1):\n",
    "        loss_epoch = []\n",
    "        acc_epoch = []\n",
    "        for j in range(int(train_length/batch_size)):\n",
    "            x,y = gen_batch(x_train,y_train,batch_size)\n",
    "            loss,acc = train_data(batch_size, x, y, sent_attn_model, sent_attn_optimiser, loss_criterion)\n",
    "            loss_epoch.append(loss)\n",
    "            acc_epoch.append(acc)\n",
    "            if (code_test and j % int(print_loss_every/batch_size) == 0) :\n",
    "                print ('Loss at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(loss_epoch)))\n",
    "                print ('Accuracy at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(acc_epoch)))\n",
    "        \n",
    "        loss_full.append(np.mean(loss_epoch))\n",
    "        acc_full.append(np.mean(acc_epoch))\n",
    "        torch.save(sent_attn_model.state_dict(), 'sent_attn_model_yelp.pth')\n",
    "        print ('Loss after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(loss_epoch)))\n",
    "        print ('Train Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(acc_epoch)))\n",
    "\n",
    "        val_acc.append(validation_accuracy(batch_size, x_val, y_val, sent_attn_model)) \n",
    "        print ('Validation Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), val_acc[-1]))\n",
    "    return loss_full,acc_full,val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 1 epoch,(22m 20s) is 0.954827\n",
      "Train Accuracy after 1 epoch,(22m 20s) is 0.579261\n",
      "Validation Accuracy after 1 epoch,(23m 34s) is 0.285962\n",
      "Loss after 2 epoch,(45m 46s) is 0.954554\n",
      "Train Accuracy after 2 epoch,(45m 46s) is 0.577879\n",
      "Validation Accuracy after 2 epoch,(47m 0s) is 0.286458\n",
      "Loss after 3 epoch,(69m 3s) is 0.950562\n",
      "Train Accuracy after 3 epoch,(69m 3s) is 0.582944\n",
      "Validation Accuracy after 3 epoch,(70m 16s) is 0.285218\n",
      "Loss after 4 epoch,(92m 29s) is 0.954126\n",
      "Train Accuracy after 4 epoch,(92m 29s) is 0.579568\n",
      "Validation Accuracy after 4 epoch,(93m 43s) is 0.280258\n",
      "Loss after 5 epoch,(115m 47s) is 0.957181\n",
      "Train Accuracy after 5 epoch,(115m 47s) is 0.579107\n",
      "Validation Accuracy after 5 epoch,(117m 0s) is 0.286210\n",
      "Loss after 6 epoch,(139m 12s) is 0.961063\n",
      "Train Accuracy after 6 epoch,(139m 12s) is 0.573735\n",
      "Validation Accuracy after 6 epoch,(140m 27s) is 0.295387\n",
      "Loss after 7 epoch,(162m 37s) is 0.956645\n",
      "Train Accuracy after 7 epoch,(162m 37s) is 0.577020\n",
      "Validation Accuracy after 7 epoch,(163m 51s) is 0.284226\n",
      "Loss after 8 epoch,(186m 39s) is 0.955103\n",
      "Train Accuracy after 8 epoch,(186m 39s) is 0.578524\n",
      "Validation Accuracy after 8 epoch,(187m 53s) is 0.275298\n",
      "Loss after 9 epoch,(209m 53s) is 0.957023\n",
      "Train Accuracy after 9 epoch,(209m 53s) is 0.575731\n",
      "Validation Accuracy after 9 epoch,(211m 7s) is 0.259921\n",
      "Loss after 10 epoch,(233m 2s) is 0.959126\n",
      "Train Accuracy after 10 epoch,(233m 2s) is 0.576038\n",
      "Validation Accuracy after 10 epoch,(234m 16s) is 0.290179\n",
      "Loss after 11 epoch,(256m 14s) is 0.958894\n",
      "Train Accuracy after 11 epoch,(256m 14s) is 0.574656\n",
      "Validation Accuracy after 11 epoch,(257m 29s) is 0.286210\n",
      "Loss after 12 epoch,(279m 27s) is 0.952579\n",
      "Train Accuracy after 12 epoch,(279m 27s) is 0.581625\n",
      "Validation Accuracy after 12 epoch,(280m 41s) is 0.285218\n",
      "Loss after 13 epoch,(302m 41s) is 0.949801\n",
      "Train Accuracy after 13 epoch,(302m 41s) is 0.582638\n",
      "Validation Accuracy after 13 epoch,(303m 56s) is 0.286458\n",
      "Loss after 14 epoch,(325m 56s) is 0.955953\n",
      "Train Accuracy after 14 epoch,(325m 56s) is 0.577849\n",
      "Validation Accuracy after 14 epoch,(327m 9s) is 0.280258\n",
      "Loss after 15 epoch,(349m 16s) is 0.951188\n",
      "Train Accuracy after 15 epoch,(349m 16s) is 0.582453\n",
      "Validation Accuracy after 15 epoch,(350m 31s) is 0.275050\n",
      "Loss after 16 epoch,(372m 44s) is 0.957279\n",
      "Train Accuracy after 16 epoch,(372m 44s) is 0.576621\n",
      "Validation Accuracy after 16 epoch,(373m 59s) is 0.290179\n",
      "Loss after 17 epoch,(396m 17s) is 0.953874\n",
      "Train Accuracy after 17 epoch,(396m 17s) is 0.578585\n",
      "Validation Accuracy after 17 epoch,(397m 33s) is 0.274306\n",
      "Loss after 18 epoch,(419m 53s) is 0.950473\n",
      "Train Accuracy after 18 epoch,(419m 53s) is 0.580734\n",
      "Validation Accuracy after 18 epoch,(421m 9s) is 0.288938\n",
      "Loss after 19 epoch,(443m 44s) is 0.954040\n",
      "Train Accuracy after 19 epoch,(443m 44s) is 0.579414\n",
      "Validation Accuracy after 19 epoch,(445m 1s) is 0.282738\n",
      "Loss after 20 epoch,(467m 44s) is 0.950203\n",
      "Train Accuracy after 20 epoch,(467m 44s) is 0.581164\n",
      "Validation Accuracy after 20 epoch,(469m 0s) is 0.286706\n",
      "Loss after 21 epoch,(491m 50s) is 0.955000\n",
      "Train Accuracy after 21 epoch,(491m 50s) is 0.578862\n",
      "Validation Accuracy after 21 epoch,(493m 6s) is 0.276290\n",
      "Loss after 22 epoch,(515m 58s) is 0.952896\n",
      "Train Accuracy after 22 epoch,(515m 58s) is 0.581502\n",
      "Validation Accuracy after 22 epoch,(517m 16s) is 0.279266\n",
      "Loss after 23 epoch,(540m 26s) is 0.951731\n",
      "Train Accuracy after 23 epoch,(540m 26s) is 0.580949\n",
      "Validation Accuracy after 23 epoch,(541m 46s) is 0.279266\n",
      "Loss after 24 epoch,(662m 44s) is 0.959447\n",
      "Train Accuracy after 24 epoch,(662m 44s) is 0.572630\n",
      "Validation Accuracy after 24 epoch,(663m 56s) is 0.273810\n",
      "Loss after 25 epoch,(683m 10s) is 0.949009\n",
      "Train Accuracy after 25 epoch,(683m 10s) is 0.583558\n",
      "Validation Accuracy after 25 epoch,(684m 0s) is 0.290427\n",
      "Loss after 26 epoch,(700m 14s) is 0.953428\n",
      "Train Accuracy after 26 epoch,(700m 14s) is 0.578585\n",
      "Validation Accuracy after 26 epoch,(701m 5s) is 0.291915\n",
      "Loss after 27 epoch,(742m 17s) is 0.951457\n",
      "Train Accuracy after 27 epoch,(742m 17s) is 0.582116\n",
      "Validation Accuracy after 27 epoch,(743m 17s) is 0.278770\n",
      "Loss after 28 epoch,(760m 56s) is 0.953575\n",
      "Train Accuracy after 28 epoch,(760m 56s) is 0.580857\n",
      "Validation Accuracy after 28 epoch,(761m 52s) is 0.287450\n",
      "Loss after 29 epoch,(778m 59s) is 0.952744\n",
      "Train Accuracy after 29 epoch,(778m 59s) is 0.582300\n",
      "Validation Accuracy after 29 epoch,(779m 56s) is 0.286706\n",
      "Loss after 30 epoch,(797m 15s) is 0.956151\n",
      "Train Accuracy after 30 epoch,(797m 15s) is 0.578401\n",
      "Validation Accuracy after 30 epoch,(798m 11s) is 0.288194\n",
      "Loss after 31 epoch,(815m 16s) is 0.953827\n",
      "Train Accuracy after 31 epoch,(815m 16s) is 0.578524\n",
      "Validation Accuracy after 31 epoch,(816m 12s) is 0.275546\n",
      "Loss after 32 epoch,(832m 23s) is 0.953829\n",
      "Train Accuracy after 32 epoch,(832m 23s) is 0.581563\n",
      "Validation Accuracy after 32 epoch,(833m 15s) is 0.280506\n",
      "Loss after 33 epoch,(849m 21s) is 0.951322\n",
      "Train Accuracy after 33 epoch,(849m 21s) is 0.582699\n",
      "Validation Accuracy after 33 epoch,(850m 12s) is 0.280258\n",
      "Loss after 34 epoch,(866m 53s) is 0.954710\n",
      "Train Accuracy after 34 epoch,(866m 53s) is 0.579568\n",
      "Validation Accuracy after 34 epoch,(867m 48s) is 0.288194\n",
      "Loss after 35 epoch,(884m 21s) is 0.951142\n",
      "Train Accuracy after 35 epoch,(884m 21s) is 0.580673\n",
      "Validation Accuracy after 35 epoch,(885m 18s) is 0.285466\n",
      "Loss after 36 epoch,(902m 19s) is 0.953608\n",
      "Train Accuracy after 36 epoch,(902m 19s) is 0.580120\n",
      "Validation Accuracy after 36 epoch,(903m 15s) is 0.288938\n",
      "Loss after 37 epoch,(920m 42s) is 0.953796\n",
      "Train Accuracy after 37 epoch,(920m 42s) is 0.579015\n",
      "Validation Accuracy after 37 epoch,(921m 38s) is 0.295635\n",
      "Loss after 38 epoch,(939m 36s) is 0.955636\n",
      "Train Accuracy after 38 epoch,(939m 36s) is 0.578862\n",
      "Validation Accuracy after 38 epoch,(940m 29s) is 0.294891\n",
      "Loss after 39 epoch,(957m 41s) is 0.954478\n",
      "Train Accuracy after 39 epoch,(957m 41s) is 0.578923\n",
      "Validation Accuracy after 39 epoch,(958m 38s) is 0.288442\n",
      "Loss after 40 epoch,(976m 22s) is 0.959206\n",
      "Train Accuracy after 40 epoch,(976m 22s) is 0.574533\n",
      "Validation Accuracy after 40 epoch,(977m 19s) is 0.273810\n",
      "Loss after 41 epoch,(994m 11s) is 0.956220\n",
      "Train Accuracy after 41 epoch,(994m 11s) is 0.576590\n",
      "Validation Accuracy after 41 epoch,(995m 2s) is 0.281498\n",
      "Loss after 42 epoch,(1012m 3s) is 0.953906\n",
      "Train Accuracy after 42 epoch,(1012m 3s) is 0.579138\n",
      "Validation Accuracy after 42 epoch,(1012m 57s) is 0.279018\n",
      "Loss after 43 epoch,(1029m 58s) is 0.954176\n",
      "Train Accuracy after 43 epoch,(1029m 58s) is 0.580489\n",
      "Validation Accuracy after 43 epoch,(1030m 55s) is 0.291915\n",
      "Loss after 44 epoch,(1047m 51s) is 0.956861\n",
      "Train Accuracy after 44 epoch,(1047m 51s) is 0.577143\n",
      "Validation Accuracy after 44 epoch,(1048m 45s) is 0.290427\n",
      "Loss after 45 epoch,(1252m 44s) is 0.953077\n",
      "Train Accuracy after 45 epoch,(1252m 44s) is 0.578831\n",
      "Validation Accuracy after 45 epoch,(1253m 36s) is 0.286458\n",
      "Loss after 46 epoch,(1270m 12s) is 0.952925\n",
      "Train Accuracy after 46 epoch,(1270m 12s) is 0.581747\n",
      "Validation Accuracy after 46 epoch,(1271m 9s) is 0.278522\n",
      "Loss after 47 epoch,(1288m 45s) is 0.956842\n",
      "Train Accuracy after 47 epoch,(1288m 45s) is 0.575731\n",
      "Validation Accuracy after 47 epoch,(1289m 40s) is 0.280754\n",
      "Loss after 48 epoch,(1307m 51s) is 0.955129\n",
      "Train Accuracy after 48 epoch,(1307m 51s) is 0.579537\n",
      "Validation Accuracy after 48 epoch,(1308m 48s) is 0.277530\n",
      "Loss after 49 epoch,(1326m 13s) is 0.956807\n",
      "Train Accuracy after 49 epoch,(1326m 13s) is 0.576682\n",
      "Validation Accuracy after 49 epoch,(1327m 9s) is 0.279266\n",
      "Loss after 50 epoch,(1344m 54s) is 0.950908\n",
      "Train Accuracy after 50 epoch,(1344m 54s) is 0.581747\n",
      "Validation Accuracy after 50 epoch,(1345m 53s) is 0.270833\n",
      "Loss after 51 epoch,(1363m 48s) is 0.952769\n",
      "Train Accuracy after 51 epoch,(1363m 48s) is 0.581410\n",
      "Validation Accuracy after 51 epoch,(1364m 44s) is 0.294147\n",
      "Loss after 52 epoch,(1382m 5s) is 0.952212\n",
      "Train Accuracy after 52 epoch,(1382m 5s) is 0.580397\n",
      "Validation Accuracy after 52 epoch,(1383m 2s) is 0.285714\n",
      "Loss after 53 epoch,(1400m 33s) is 0.957953\n",
      "Train Accuracy after 53 epoch,(1400m 33s) is 0.575178\n",
      "Validation Accuracy after 53 epoch,(1401m 30s) is 0.268601\n",
      "Loss after 54 epoch,(1419m 46s) is 0.954167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy after 54 epoch,(1419m 46s) is 0.577726\n",
      "Validation Accuracy after 54 epoch,(1420m 43s) is 0.287698\n",
      "Loss after 55 epoch,(1438m 26s) is 0.952133\n",
      "Train Accuracy after 55 epoch,(1438m 26s) is 0.581717\n",
      "Validation Accuracy after 55 epoch,(1439m 23s) is 0.277530\n",
      "Loss after 56 epoch,(1457m 4s) is 0.959518\n",
      "Train Accuracy after 56 epoch,(1457m 4s) is 0.573520\n",
      "Validation Accuracy after 56 epoch,(1458m 3s) is 0.274802\n",
      "Loss after 57 epoch,(1475m 46s) is 0.955042\n",
      "Train Accuracy after 57 epoch,(1475m 46s) is 0.579752\n",
      "Validation Accuracy after 57 epoch,(1476m 42s) is 0.269841\n",
      "Loss after 58 epoch,(1494m 1s) is 0.951682\n",
      "Train Accuracy after 58 epoch,(1494m 1s) is 0.582852\n",
      "Validation Accuracy after 58 epoch,(1494m 56s) is 0.289931\n"
     ]
    }
   ],
   "source": [
    "loss_full, acc_full, val_acc = train_early_stopping(batch_size, X_train_pad, y_train_tensor, X_val_pad,\n",
    "                                y_val_tensor, sent_attn, sent_optimizer, criterion, epoch, 10000, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
