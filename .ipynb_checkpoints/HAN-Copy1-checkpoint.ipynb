{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = \"cpu\"\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (6,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path = \"dataset/\"\n",
    "df = pd.read_csv(path+\"USvideos.csv\")\n",
    "df = df.assign(country=\"US\")\n",
    "# df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')  \n",
    "# df.trending_date = df.trending_date.dt.date   \n",
    "# df['publish_time'] = pd.to_datetime(df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "# df=df.assign(publish_date=df['publish_time'].dt.date)\n",
    "# df['publish_time'] = df['publish_time'].dt.time\n",
    "\n",
    "# ###导入category名称###\n",
    "# df=df.assign(cat_name='a')\n",
    "# id_to_category = {}\n",
    "# file=path+'US_category_id.json'\n",
    "# with open(file, 'r') as f:\n",
    "#     data=json.load(f)\n",
    "#     for category in data['items']:\n",
    "#         id_to_category[category['id']] = category['snippet']['title']\n",
    "# print(id_to_category)\n",
    "# ###实际上每个国家的category id-name 字典是一样的\n",
    "# df['category_id'] = df['category_id'].astype(str)\n",
    "# df.insert(4, 'category', df['category_id'].map(id_to_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>views</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO 鈻?\\n\\nSUBSCRIBE 鈻?http...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  views Unnamed: 2  \\\n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...      1        NaN   \n",
       "1  One year after the presidential election, John...      2        NaN   \n",
       "2  WATCH MY PREVIOUS VIDEO 鈻?\\n\\nSUBSCRIBE 鈻?http...      2        NaN   \n",
       "3  Today we find out if Link is a Nickelback amat...      0        NaN   \n",
       "4  I know it's been a while since we did this sho...      1        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  Unnamed: 7 Unnamed: 8  \\\n",
       "0        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "2        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "3        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "4        NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "\n",
       "  Unnamed: 9  ... Unnamed: 18 Unnamed: 19 Unnamed: 20 Unnamed: 21 Unnamed: 22  \\\n",
       "0        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "1        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "2        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "3        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "4        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 23 Unnamed: 24 Unnamed: 25  Unnamed: 26  country  \n",
       "0         NaN         NaN         NaN          NaN       US  \n",
       "1         NaN         NaN         NaN          NaN       US  \n",
       "2         NaN         NaN         NaN          NaN       US  \n",
       "3         NaN         NaN         NaN          NaN       US  \n",
       "4         NaN         NaN         NaN          NaN       US  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## mark the columns which contains text for classification and target class\n",
    "col_text = 'description'\n",
    "col_target = 'views'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_arr = np.sort(df[col_target].unique()).tolist()\n",
    "classes = len(cls_arr)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide dataset in 80% train 10% validation 10% test as done in the paper\n",
    "length = df.shape[0]\n",
    "train_len = int(0.8*length)\n",
    "val_len = int(0.1*length)\n",
    "\n",
    "train = df[:train_len]\n",
    "val = df[train_len:train_len+val_len]\n",
    "test = df[train_len+val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string, max_seq_len):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = str(string)\n",
    "    string = BeautifulSoup(string, \"lxml\").text\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\\"\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\\"s\", \" \\\"s\", string)\n",
    "    string = re.sub(r\"\\\"ve\", \" \\\"ve\", string)\n",
    "    string = re.sub(r\"n\\\"t\", \" n\\\"t\", string)\n",
    "    string = re.sub(r\"\\\"re\", \" \\\"re\", string)\n",
    "    string = re.sub(r\"\\\"d\", \" \\\"d\", string)\n",
    "    string = re.sub(r\"\\\"ll\", \" \\\"ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    s =string.strip().lower().split(\" \")\n",
    "    if len(s) > max_seq_len:\n",
    "        return s[0:max_seq_len] \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a 3D list of format paragraph[sentence[word]]\n",
    "def create3DList(df,col, max_sent_len,max_seq_len):\n",
    "    x=[]\n",
    "    for docs in df[col].as_matrix():\n",
    "        x1=[]\n",
    "        idx = 0\n",
    "        docs = str(docs)\n",
    "        for seq in \"|||\".join(re.split(\"[.?!]\", docs)).split(\"|||\"):\n",
    "            x1.append(clean_str(seq,max_sent_len))\n",
    "            if(idx>=max_seq_len-1):\n",
    "                break\n",
    "            idx= idx+1\n",
    "        x.append(x1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix the maximum length of sentences in a paragraph and words in a sentence\n",
    "max_sent_len = 12\n",
    "max_seq_len = 25\n",
    "# print(df[col].as_matrix()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://www\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://youtu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://www\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://goo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://facebook\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://twitter\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://ctt\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://twitter\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://instagram\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://snpcht\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://facebook\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://smu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://esteelalonde\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://po\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://shop\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://GinWigmore\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://smarturl\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://store\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://hevesh5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://tiltify\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://youtube\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://theguardian\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://is\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://loudwire\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://sub2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://snapchat\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://Teespring\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://GhostAndStars\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://open\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://itunes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://soundcloud\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://olenkalovers\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://olenkalovers\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://spoti\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://apple\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://votetheprocess\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://zaydewolf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://dk4l\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://plus\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://hondaloves\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://snapchat\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://shopcaseyneistat\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://republic\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://readyplayeronemovie\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://amzn\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://github\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://ShopLoganPaul\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://shots\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://shop\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://discuss\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://represent\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://carlyanderin\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://shots\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://bit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://crmbs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://tickets\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://fb\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://pointlessblogtv\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://kyoto-kitcho\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://instagram\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://t\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://patreon\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://omny\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://people\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://guardian\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://turbotax\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://morphebrushes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://pastebin\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://Squarespace\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://lifeformed\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://hackaday\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://billwurtz\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://crowdmade\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://goo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://damonandjo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://kinded\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://annaed\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://store\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://librivox\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://thegame730am\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://youtu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://shortyawards\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://time\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://Spoti\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://YouTube\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://soundcloud\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://reddit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://https://www\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://solidgoldaquatics\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://xgam\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bachelorinsider\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://pinterest\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://go90\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://au\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://like\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://evanedinger\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://navalny\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://2018\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://youtube\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://eepurl\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://intuit\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://apple\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://tapastic\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://build-its-inprogress\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://crowdmade\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://tidd\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bramfam\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://markiplier\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://freshmanxxlmag\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://nyti\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://poobear\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://discordapp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://petitecosmetics\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://vote\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://vevo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://bhcosmetics\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://woodgears\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://ptxofficial\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://AlisonWonderland\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://twicejapan\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://teamedge\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://moreclutterfree\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://warehouse\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://rugwear\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://m\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://beaklondike\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://skl\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://DeFrancoElite\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://BetterHelp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://PostDeFranco\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://dollarshaveclub\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://hellohonne\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://tour\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://peppermint\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"http://remyny\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 32580\n",
      "x_val: 4072\n",
      "x_test: 4074\n"
     ]
    }
   ],
   "source": [
    "## divides review in sentences and sentences into word creating a 3DList\n",
    "x_train = create3DList(train,col_text, max_sent_len,max_seq_len)\n",
    "x_val = create3DList(val, col_text, max_sent_len,max_seq_len)\n",
    "x_test = create3DList(test, col_text, max_sent_len,max_seq_len)\n",
    "print(\"x_train: {}\".format(len(x_train)))\n",
    "print(\"x_val: {}\".format(len(x_val)))\n",
    "print(\"x_test: {}\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english') + list(string.punctuation)\n",
    "stemmer = SnowballStemmer('english')\n",
    "x_train_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_train]\n",
    "x_test_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_test]\n",
    "x_val_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_val]\n",
    "\n",
    "## calculate frequency of words\n",
    "from collections import defaultdict\n",
    "frequency1 = defaultdict(int)\n",
    "for texts in x_train_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_test_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_val_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "            \n",
    "## remove  words with frequency less than 5.\n",
    "x_train_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_train_texts]\n",
    "\n",
    "x_test_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_test_texts]\n",
    "x_val_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(more_itertools.collapse(x_train_texts[:] + x_test_texts[:] + x_val_texts[:],levels=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(texts,size=200, min_count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save(\"dictonary_youtube\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert 3D text list to 3D list of index \n",
    "x_train_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weights = torch.FloatTensor(word2vec.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2vec.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[col_target].tolist()\n",
    "y_test = test[col_target].tolist()\n",
    "y_val = val[col_target].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the the multiple attention with word vectors.\n",
    "def attention_mul(rnn_outputs, att_weights):\n",
    "    attn_vectors = None\n",
    "    for i in range(rnn_outputs.size(0)):\n",
    "        h_i = rnn_outputs[i]\n",
    "        a_i = att_weights[i]\n",
    "        h_i = a_i * h_i\n",
    "        h_i = h_i.unsqueeze(0)\n",
    "        if(attn_vectors is None):\n",
    "            attn_vectors = h_i\n",
    "        else:\n",
    "            attn_vectors = torch.cat((attn_vectors,h_i),0)\n",
    "    return torch.sum(attn_vectors, 0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The word RNN model for generating a sentence vector\n",
    "class WordRNN(nn.Module):\n",
    "    def __init__(self, vocab_size,embedsize, batch_size, hid_size):\n",
    "        super(WordRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        ## Word Encoder\n",
    "        self.embed = nn.Embedding(vocab_size, embedsize)\n",
    "        self.wordRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Word Attention\n",
    "        self.wordattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "    def forward(self,inp, hid_state):\n",
    "        emb_out  = self.embed(inp)\n",
    "\n",
    "        out_state, hid_state = self.wordRNN(emb_out, hid_state)\n",
    "\n",
    "        word_annotation = self.wordattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(word_annotation),dim=1)\n",
    "\n",
    "        sent = attention_mul(out_state,attn)\n",
    "        return sent, hid_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The HAN model\n",
    "class SentenceRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedsize, batch_size, hid_size,c):\n",
    "        super(SentenceRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        self.cls = c\n",
    "        self.wordRNN = WordRNN(vocab_size,embedsize, batch_size, hid_size)\n",
    "        ## Sentence Encoder\n",
    "        self.sentRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Sentence Attention\n",
    "        self.sentattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "        self.doc_linear = nn.Linear(2*hid_size, c)\n",
    "    \n",
    "    def forward(self,inp, hid_state_sent, hid_state_word):\n",
    "        s = None\n",
    "        ## Generating sentence vector through WordRNN\n",
    "        for i in range(len(inp[0])):\n",
    "            r = None\n",
    "            for j in range(len(inp)):\n",
    "                if(r is None):\n",
    "                    r = [inp[j][i]]\n",
    "                else:\n",
    "                    r.append(inp[j][i])\n",
    "            r1 = np.asarray([sub_list + [0] * (max_seq_len - len(sub_list)) for sub_list in r])\n",
    "            _s, state_word = self.wordRNN(torch.LongTensor(r1).view(-1,batch_size), hid_state_word)\n",
    "            if(s is None):\n",
    "                s = _s\n",
    "            else:\n",
    "                s = torch.cat((s,_s),0)\n",
    "\n",
    "                out_state, hid_state = self.sentRNN(s, hid_state_sent)\n",
    "        sent_annotation = self.sentattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(sent_annotation),dim=1)\n",
    "\n",
    "        doc = attention_mul(out_state,attn)\n",
    "        d = self.doc_linear(doc)\n",
    "        cls = F.log_softmax(d.view(-1,self.cls),dim=1)\n",
    "        return cls, hid_state\n",
    "    \n",
    "    def init_hidden_sent(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size))\n",
    "    \n",
    "    def init_hidden_word(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## converting list to tensor\n",
    "# # y_train[:10]\n",
    "y_train_tensor =  torch.from_numpy(np.array(y_train))#[torch.FloatTensor([cls_arr[label]]) for label in y_train]\n",
    "y_val_tensor =  torch.from_numpy(np.array(y_val))#[torch.FloatTensor([cls_arr[label]]) for label in y_val]\n",
    "y_test_tensor =  torch.from_numpy(np.array(y_test))#[torch.FloatTensor([cls_arr[label]]) for label in y_test]\n",
    "\n",
    "\n",
    "# ## converting list to tensor\n",
    "# y_train_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_train]\n",
    "# y_val_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_val]\n",
    "# y_test_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)])\n",
    "max_sent_len = max([len(sent) for sent in (x_train_vec + x_val_vec + x_test_vec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)]),90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(sent) for sent in (x_train_vec +x_val_vec + x_test_vec)]),90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding the input \n",
    "X_train_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_train_vec]\n",
    "X_val_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_val_vec]\n",
    "X_test_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_test_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(batch_size, review, targets, sent_attn_model, sent_optimizer, criterion):\n",
    "\n",
    "    state_word = sent_attn_model.init_hidden_word()\n",
    "    state_sent = sent_attn_model.init_hidden_sent()\n",
    "    sent_optimizer.zero_grad()\n",
    "            \n",
    "    y_pred, state_sent = sent_attn_model(review, state_sent, state_word)\n",
    "\n",
    "    loss = criterion(y_pred, torch.LongTensor(targets)) \n",
    "    \n",
    "    max_index = y_pred.max(dim = 1)[1]\n",
    "    correct = (max_index == torch.LongTensor(targets)).sum()\n",
    "    acc = float(correct)/batch_size\n",
    "\n",
    "    loss.backward()\n",
    "#     print(loss)\n",
    "    sent_optimizer.step()\n",
    "    \n",
    "    return loss.item(),acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 100\n",
    "embedsize = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_attn = SentenceRNN(vocab_size,embedsize,batch_size,hid_size,classes)\n",
    "sent_attn.wordRNN.embed.from_pretrained(weights)\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "momentum = 0.9\n",
    "\n",
    "sent_optimizer = torch.optim.SGD(sent_attn.parameters(), lr=learning_rate, momentum= momentum)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(x,y,batch_size):\n",
    "    k = random.sample(range(len(x)-1),batch_size)\n",
    "    x_batch=[]\n",
    "    y_batch=[]\n",
    "\n",
    "    for t in k:\n",
    "        x_batch.append(x[t])\n",
    "        y_batch.append(y[t])\n",
    "\n",
    "    return [x_batch,y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(batch_size, x_val,y_val,sent_attn_model):\n",
    "    acc = []\n",
    "    val_length = len(x_val)\n",
    "    for j in range(int(val_length/batch_size)):\n",
    "        x,y = gen_batch(x_val,y_val,batch_size)\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        \n",
    "        y_pred, state_sent = sent_attn_model(x, state_sent, state_word)\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(y)).sum()\n",
    "        acc.append(float(correct)/batch_size)\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_early_stopping(batch_size, x_train, y_train, x_val, y_val, sent_attn_model, \n",
    "                         sent_attn_optimiser, loss_criterion, num_epoch,\n",
    "                         print_loss_every = 50, code_test=True):\n",
    "    start = time.time()\n",
    "    loss_full = []\n",
    "    loss_epoch = []\n",
    "    acc_epoch = []\n",
    "    acc_full = []\n",
    "    val_acc = []\n",
    "    epoch_counter = 0\n",
    "    train_length = len(x_train)\n",
    "    for i in range(1, num_epoch + 1):\n",
    "        loss_epoch = []\n",
    "        acc_epoch = []\n",
    "        for j in range(int(train_length/batch_size)):\n",
    "            x,y = gen_batch(x_train,y_train,batch_size)\n",
    "            loss,acc = train_data(batch_size, x, y, sent_attn_model, sent_attn_optimiser, loss_criterion)\n",
    "            loss_epoch.append(loss)\n",
    "            acc_epoch.append(acc)\n",
    "            if (code_test and j % int(print_loss_every/batch_size) == 0) :\n",
    "                print ('Loss at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(loss_epoch)))\n",
    "                print ('Accuracy at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(acc_epoch)))\n",
    "        \n",
    "        loss_full.append(np.mean(loss_epoch))\n",
    "        acc_full.append(np.mean(acc_epoch))\n",
    "        torch.save(sent_attn_model.state_dict(), 'sent_attn_model_yelp.pth')\n",
    "        print ('Loss after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(loss_epoch)))\n",
    "        print ('Train Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(acc_epoch)))\n",
    "\n",
    "        val_acc.append(validation_accuracy(batch_size, x_val, y_val, sent_attn_model)) \n",
    "        print ('Validation Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), val_acc[-1]))\n",
    "    return loss_full,acc_full,val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_full, acc_full, val_acc = train_early_stopping(batch_size, X_train_pad, y_train_tensor, X_val_pad,\n",
    "                                y_val_tensor, sent_attn, sent_optimizer, criterion, epoch, 10000, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
