{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-pocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'Film & Animation', '2': 'Autos & Vehicles', '10': 'Music', '15': 'Pets & Animals', '17': 'Sports', '18': 'Short Movies', '19': 'Travel & Events', '20': 'Gaming', '21': 'Videoblogging', '22': 'People & Blogs', '23': 'Comedy', '24': 'Entertainment', '25': 'News & Politics', '26': 'Howto & Style', '27': 'Education', '28': 'Science & Technology', '29': 'Nonprofits & Activism', '30': 'Movies', '31': 'Anime/Animation', '32': 'Action/Adventure', '33': 'Classics', '34': 'Comedy', '35': 'Documentary', '36': 'Drama', '37': 'Family', '38': 'Foreign', '39': 'Horror', '40': 'Sci-Fi/Fantasy', '41': 'Thriller', '42': 'Shorts', '43': 'Shows', '44': 'Trailers'}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path+\"USvideos.csv\")\n",
    "df = df.assign(country=\"US\")\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')  \n",
    "df.trending_date = df.trending_date.dt.date   \n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "df=df.assign(publish_date=df['publish_time'].dt.date)\n",
    "df['publish_time'] = df['publish_time'].dt.time\n",
    "\n",
    "###导入category名称###\n",
    "df=df.assign(cat_name='a')\n",
    "id_to_category = {}\n",
    "file=path+'US_category_id.json'\n",
    "with open(file, 'r') as f:\n",
    "    data=json.load(f)\n",
    "    for category in data['items']:\n",
    "        id_to_category[category['id']] = category['snippet']['title']\n",
    "print(id_to_category)\n",
    "###实际上每个国家的category id-name 字典是一样的\n",
    "df['category_id'] = df['category_id'].astype(str)\n",
    "df.insert(4, 'category', df['category_id'].map(id_to_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189e993db88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summary = df.describe(include=\"all\")\n",
    "\n",
    "# Use heatmap to check missing data\n",
    "sb.heatmap(df_summary.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id 7\n",
      "trending_date 7\n",
      "title 7\n",
      "channel_title 7\n",
      "category 7\n",
      "category_id 7\n",
      "publish_time 7\n",
      "tags 7\n",
      "views 3\n",
      "likes 3\n",
      "dislikes 3\n",
      "comment_count 3\n",
      "thumbnail_link 7\n",
      "comments_disabled 7\n",
      "ratings_disabled 7\n",
      "video_error_or_removed 7\n",
      "description 7\n",
      "country 7\n",
      "publish_date 7\n",
      "cat_name 7\n"
     ]
    }
   ],
   "source": [
    "# See counts of missing value\n",
    "for c in df_summary.columns:\n",
    "    print(c,np.sum(df_summary[c].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df.sample(5)\n",
    "# Replace missing data\n",
    "df_summary['description'].fillna(\"\", inplace=True)\n",
    "df_summary['title'].fillna(\"\", inplace=True)\n",
    "df_summary['category_id'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# for k,v in df_summary.items():\n",
    "#     print(type(df_summary[k]))\n",
    "#     print(\"hhh\")\n",
    "#     df_summary[k].fillna(int(df_summary[k].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189e9a5a4c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop a column most value are missing\n",
    "# df_summary.drop(['thumbnail_link'], axis=1, inplace=True)\n",
    "sb.heatmap(df_summary.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize\n",
    "# Import the libraries\n",
    "\n",
    "# plt.plot(df['views'],df['view'])\n",
    "# matplotlib histogram\n",
    "plt.hist(df['views'], color = 'blue', edgecolor = 'black',\n",
    "         bins = int(30))\n",
    "\n",
    "# # seaborn histogram\n",
    "# sb.distplot(df['view'], hist=True, kde=False, \n",
    "#              bins=int(180/5), color = 'blue',\n",
    "#              hist_kws={'edgecolor':'black'})\n",
    "# Add labels\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('views')\n",
    "plt.ylabel('number')\n",
    "\n",
    "# np.sum(df['views']>2.35e6)\n",
    "y_train = np.zeros_like(df['views'])\n",
    "y_train[df['views']>7e5] = 1\n",
    "y_train[df['views']>2.35e6] = 2\n",
    "# y_train.shape\n",
    "# np.median(df['views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Hudson Union www.hudsonunionsociety.com is where everyone comes to be inspired, to change our world.\\\\n\\\\nCheck us out on Twitter @ActualJoePascal\\\\n\\\\nBryan Cranston won four Emmy Awards for Outstanding Lead Actor in a Drama Series for his portrayal of Walter White in AMC’s Breaking Bad. He holds the honor of being the first actor in a cable series, and the second lead actor in the history of the Emmy Awards, to receive three consecutive wins. In 2014 he won a Tony Award for his role as Lyndon B. Johnson in the bio-play All the Way. In film, Cranston has won two Screen Actors Guild Awards and received an Academy Award nomination for his leading role in Trumbo. Among his numerous television and film appearances, he was nominated for a Golden Globe and three Emmys for his portrayal of Hal in FOX’s Malcolm in the Middle.\\\\n\\\\nBryan Cranston landed his first role at seven, when his father, a struggling actor and director, cast him in a United Way commercial. Soon, Bryan was haunting the local movie theater, memorizing and reenacting favorite scenes with his older brother. Acting was clearly the boy’s destiny, until one day his father disappeared. Suddenly, destiny took a back seat to survival.\\\\n\\\\nSeeking something more stable, perhaps subconsciously trying to distance himself from his absent father, Cranston decided on a career in law enforcement. But then, a young man on a classic cross-country motorcycle trip, Cranston one day found himself stranded at a rest area in the Blue Ridge Mountains. Suddenly he thought: This was what he wanted to do, what he would do, with the rest of his life. Act.\\\\n\\\\nEach paid attendee will receive, Brian Cranston’s riveting memoir, A Life in Parts, Cranston traces his zigzag journey from his chaotic childhood to to mega-stardom and a cult-like following\\\\n\\\\nAt the Hudson Union with great humor, and much humility, Cranston will chronicle his unlikely rise from a soap opera regular, trying to learn the ropes and the politics of show business on the fly.  \\\\n\\\\nCranston will dive deep into the grittiest, most fascinating details of his greatest role, explaining how he searched inward for the personal darkness that would help him create one of the most riveting performances ever captured on screen: Walter White, chemistry teacher turned drug kingpin.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['description']\n",
    "# np.arange(1,df.size(),1)\n",
    "# df['views']>2e8\n",
    "df['description'][1435]#.idxmin(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4095"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_X, test_X = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_y, test_y = train_test_split(y_train, test_size=0.1, random_state=42)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40949,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['views'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training\n",
    "count_vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\", tokenizer=nltk.word_tokenize,\n",
    "    preprocessor=None, stop_words='english', max_features=3000) \n",
    "train_data_features = count_vectorizer.fit_transform(train_data['description'].values.astype('U')) #3000*train_feature\n",
    "test_data_features = count_vectorizer.transform(test_data['description'].values.astype('U')) #3000*train_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(train_data_features, train_data['views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43283299166900924"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reg.score(test_data_features, test_data['views'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1690934171548062"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = AdaBoostRegressor(n_estimators=500, random_state=0,learning_rate=1e-7,loss='square')\n",
    "regr.fit(train_data_features, train_data['views'])\n",
    "regr.score(test_data_features, test_data['views'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6271319526630299"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr2 = GradientBoostingRegressor(n_estimators=500, random_state=0,learning_rate=0.1,loss='ls')\n",
    "regr2.fit(train_data_features, train_data['views'])\n",
    "regr2.score(test_data_features, test_data['views'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6332112332112332"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(test_X)\n",
    "\n",
    "clf = SVC(verbose=True)\n",
    "clf.fit(train_data_features, train_y) \n",
    "clf.score(test_data_features, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7787545787545788"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=500, random_state=0,learning_rate=0.1,loss='deviance')\n",
    "clf.fit(train_data_features, train_y) \n",
    "clf.score(test_data_features, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import gensim.downloader as api\n",
    "\n",
    "info = api.info()  # show info about available models/datasets\n",
    "model = api.load(\"glove-twitter-25\")  # download the model and return as object ready for use\n",
    "# model.most_similar(\"cat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "#             print(wv.vocab[word].index)\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "#         logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(25,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float64)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1193514, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "list(islice(model.vocab, 13000, 13020))\n",
    "model.most_similar(\"cat\")\n",
    "model.syn0norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    if not text:\n",
    "        print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "        text = ''\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "# def custom_tokenize(text):\n",
    "#     if not text:\n",
    "#         print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "#         text = ''\n",
    "#     return word_tokenize(text)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n",
      "The text to be tokenized is a None type. Defaulting to blank string.\n"
     ]
    }
   ],
   "source": [
    "# print(type(test_data['description']))\n",
    "# print(type(test_data.at['description',4729]))\n",
    "# test_data['description'].dropna(inplace=True)\n",
    "# train_data['description'].dropna(inplace=True)\n",
    "# print(train_data['description'].iloc[4729])\n",
    "# test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['description']), axis=1).values\n",
    "# train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['description']), axis=1).values\n",
    "# test_tokenized = df.description.apply(nltk.word_tokenize)\n",
    "\n",
    "# train_data.dropna(subset=['description'])\n",
    "# test_data.dropna(subset=['description'])\n",
    "test_tokenized = test_data[\"description\"].fillna(\"\").map(w2v_tokenize_text)\n",
    "train_tokenized = train_data[\"description\"].fillna(\"\").map(w2v_tokenize_text)\n",
    "\n",
    "\n",
    "# df.sample(5)\n",
    "# na.omit(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_word_average = word_averaging_list(model,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(model,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05163631616800457"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train_word_average, train_data['views'])\n",
    "# test_data_features = count_vectorizer.transform(test_data['description'].values.astype('U')) #3000*train_feature\n",
    "reg.score(X_test_word_average, test_data['views'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7079379039078945"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr2 = GradientBoostingRegressor(n_estimators=500, random_state=0,learning_rate=0.1,loss='ls')\n",
    "regr2.fit(X_train_word_average, train_data['views'])\n",
    "regr2.score(X_test_word_average, test_data['views'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49865689865689866"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(verbose=True)\n",
    "clf.fit(X_train_word_average, train_y) \n",
    "clf.score(X_test_word_average, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875457875457875"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=500, random_state=0,learning_rate=0.1,loss='deviance')\n",
    "clf.fit(X_train_word_average, train_y) \n",
    "clf.score(X_test_word_average, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def word_append(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "#     count = 0\n",
    "    for word in words:\n",
    "#         count+=1\n",
    "#         if count>69:\n",
    "#             break\n",
    "        if len(mean)>99:\n",
    "            break\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "#             print(wv.vocab[word].index)\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "#             print(wv.syn0norm[wv.vocab[word].index].shape)\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "#     print(\"=============================\")\n",
    "#     print(len(mean))\n",
    "#     if count<70:\n",
    "    lengt = len(mean)\n",
    "    if lengt<100:\n",
    "        for i in range(100-lengt):\n",
    "            x = np.zeros((25,))\n",
    "            mean.append(x)\n",
    "#     print(len(mean))\n",
    "#     print(count)\n",
    "#     print(mean.shape)\n",
    "    if not mean:\n",
    "#         logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        print(\"not mean\")\n",
    "        return np.zeros(25,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean)).astype(np.float32)\n",
    "#     mean = np.array(mean)\n",
    "#     print(mean.shape)\n",
    "#     print(mean)\n",
    "#     cccount+=1\n",
    "#     print(cccount)\n",
    "    \n",
    "    return mean\n",
    "\n",
    "def  word_list(wv, text_list):\n",
    "    ret = []\n",
    "#     i = 0\n",
    "    for review in text_list:\n",
    "#         i+=1\n",
    "#         print(i,\":\")\n",
    "        x = word_append(wv, review)\n",
    "#         print(x.size())\n",
    "        ret.append(x)\n",
    "    return ret\n",
    "#     return np.vstack([word_append(wv, review) for review in text_list ])\n",
    "\n",
    "X_train_word = word_list(model,train_tokenized)\n",
    "X_test_word = word_list(model,test_tokenized)\n",
    "\n",
    "# X_train_word = word_list(model,['SHANTELL', \"'S\", 'CHANNEL', 'https'])\n",
    "\n",
    "# print(train_tokenized[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40949\n",
      "70.0\n",
      "(36854, 70, 25)\n",
      "(4095, 70, 25)\n",
      "(4095, 70, 25)\n",
      "(40949, 70, 25)\n"
     ]
    }
   ],
   "source": [
    "ave = 0\n",
    "count=0\n",
    "for i in X_train_word:\n",
    "    ave += i.shape[0]\n",
    "    count+=1\n",
    "for i in X_test_word:\n",
    "    ave += i.shape[0]\n",
    "    count+=1\n",
    "print(count)\n",
    "print(ave/count)\n",
    "\n",
    "print(np.array(X_train_word).shape)\n",
    "print(np.array(X_test_word).shape)\n",
    "\n",
    "X_train_words = np.array(X_train_word).reshape(-1,70,25)\n",
    "X_test_words = np.array(X_test_word).reshape(-1,70,25)\n",
    "print(X_test_words.shape)\n",
    "features = np.concatenate((X_train_words,X_test_words),axis=0)\n",
    "print(features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set :  (32759, 70, 25) (32759,)\n",
      "Validation set :  (4095, 70, 25) (4095,)\n",
      "Test set :  (4095, 70, 25) (4095,)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "encoded_labels = np.array(y_train)\n",
    "\n",
    "\n",
    "length = len(features)\n",
    "split = int(split_frac*length)\n",
    "\n",
    "train_x,valid_x = features[:split],features[split:]\n",
    "train_y,valid_y = encoded_labels[:split],encoded_labels[split:]\n",
    "\n",
    "test_x,test_y = valid_x[len(valid_x)//2:],valid_y[len(valid_y)//2:]\n",
    "valid_x,valid_y = valid_x[:len(valid_x)//2],valid_y[:len(valid_y)//2]\n",
    "## print out the shapes of your resultant feature data\n",
    "print('Train set : ',train_x.shape,train_y.shape)\n",
    "print('Validation set : ',valid_x.shape,valid_y.shape)\n",
    "print('Test set : ',test_x.shape,test_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size,drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 70, 25])\n",
      "Sample input: \n",
      " tensor([[[ 2.4023e-02,  3.2274e-03,  6.9099e-02,  ..., -1.6247e-02,\n",
      "          -2.3157e-02,  1.7688e-02],\n",
      "         [-1.6728e-02, -8.1469e-03,  5.4789e-03,  ...,  1.1162e-03,\n",
      "          -3.7409e-02,  3.3161e-02],\n",
      "         [ 6.7656e-03,  4.7038e-02,  5.3458e-02,  ..., -1.1401e-02,\n",
      "          -2.9057e-02,  1.6346e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-3.4174e-04,  6.7878e-04,  7.2177e-03,  ...,  6.3135e-03,\n",
      "          -2.8319e-02, -1.0490e-02],\n",
      "         [-2.4200e-02,  3.3385e-02,  3.5027e-02,  ...,  8.2573e-03,\n",
      "          -3.3122e-02,  3.7192e-02],\n",
      "         [-1.4596e-02,  3.0460e-02,  2.5229e-02,  ...,  2.5890e-02,\n",
      "           1.6581e-02, -8.5654e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.2421e-02,  1.1042e-02,  2.2894e-02,  ..., -2.5234e-02,\n",
      "          -3.2678e-02, -1.9803e-02],\n",
      "         [ 1.7100e-03,  3.5466e-03,  8.1917e-03,  ..., -5.7491e-02,\n",
      "          -4.5267e-02, -2.7273e-02],\n",
      "         [-6.4619e-03,  1.3424e-02, -6.8962e-03,  ..., -9.1653e-03,\n",
      "          -1.3305e-03, -7.2370e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7724e-02, -1.3242e-02,  4.4602e-02,  ...,  1.1284e-02,\n",
      "          -9.6697e-03, -1.6233e-03],\n",
      "         [-4.0261e-03, -3.1481e-03,  8.0020e-03,  ..., -1.7639e-03,\n",
      "          -1.7705e-03, -5.7685e-03],\n",
      "         [-8.7174e-03,  7.4641e-03,  1.7346e-02,  ...,  5.8294e-03,\n",
      "          -2.2855e-02,  1.5988e-03],\n",
      "         ...,\n",
      "         [ 3.1421e-02, -2.1419e-02,  8.2800e-03,  ..., -5.5965e-03,\n",
      "          -2.8314e-03, -1.2222e-02],\n",
      "         [ 1.2648e-02,  2.0313e-02,  2.3001e-02,  ..., -9.0834e-03,\n",
      "          -1.5662e-02, -9.0230e-03],\n",
      "         [-1.4635e-02, -5.1545e-03,  1.1263e-03,  ..., -6.5045e-03,\n",
      "          -9.0091e-04, -1.3059e-02]],\n",
      "\n",
      "        [[ 2.0304e-02,  1.2719e-03,  2.8908e-02,  ...,  7.8161e-05,\n",
      "          -2.9330e-02,  1.3652e-02],\n",
      "         [-2.9804e-03, -4.8057e-03, -3.0137e-03,  ..., -9.9329e-03,\n",
      "           5.9846e-03, -1.3273e-03],\n",
      "         [ 7.7225e-03, -2.1271e-03, -3.4961e-03,  ..., -1.4653e-02,\n",
      "          -1.2955e-02, -1.6586e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.2946e-02,  7.6280e-03,  1.2816e-02,  ..., -2.7554e-02,\n",
      "           8.6890e-03, -1.4184e-02],\n",
      "         [-5.3695e-04, -2.1126e-03, -5.6863e-03,  ...,  3.5311e-03,\n",
      "          -2.9711e-02, -2.8431e-02],\n",
      "         [-4.5013e-03, -3.5197e-03,  8.9465e-03,  ..., -1.9722e-03,\n",
      "          -1.9795e-03, -6.4494e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 0, 1, 2, 2, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2,\n",
      "        0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0,\n",
      "        1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.7):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # define all layers\n",
    "#         self.embed = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,hidden_dim,n_layers,dropout=drop_prob,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim,output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.drp = nn.Dropout(p=0.7)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size=x.shape[0]\n",
    "        \n",
    "#         x = self.embed(x)\n",
    "       \n",
    "        x,hidden = self.lstm(x,hidden)\n",
    "        \n",
    "        x = x.reshape(-1,self.hidden_dim)\n",
    "        \n",
    "        x = self.drp(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        sig_out = self.sigmoid(x)\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        sig_out = sig_out.reshape(batch_size,-1)\n",
    "        sig_out = sig_out[:,-1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (lstm): LSTM(25, 50, num_layers=2, batch_first=True, dropout=0.7)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (drp): Dropout(p=0.7, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = 1193514+1#???\n",
    "output_size = 1\n",
    "embedding_dim = 25\n",
    "hidden_dim = 50\n",
    "n_layers = 2\n",
    "\n",
    "net = None\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.0001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "e: 0\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 1/10... Step: 655... Loss: 0.729494... Val Loss: 0.526238\n",
      "\t\t...Saving Model...\n",
      "e: 1\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 2/10... Step: 1310... Loss: 0.698907... Val Loss: 0.535075\n",
      "e: 2\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 3/10... Step: 1965... Loss: 0.713312... Val Loss: 0.538056\n",
      "e: 3\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 4/10... Step: 2620... Loss: 0.639041... Val Loss: 0.538658\n",
      "e: 4\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 5/10... Step: 3275... Loss: 0.753745... Val Loss: 0.539741\n",
      "e: 5\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 6/10... Step: 3930... Loss: 0.690363... Val Loss: 0.541132\n",
      "e: 6\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 7/10... Step: 4585... Loss: 0.701780... Val Loss: 0.542398\n",
      "e: 7\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 8/10... Step: 5240... Loss: 0.675704... Val Loss: 0.538114\n",
      "e: 8\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 9/10... Step: 5895... Loss: 0.713514... Val Loss: 0.539086\n",
      "e: 9\n",
      "torch.Size([2, 50, 50])\n",
      "\n",
      "Batch : 655/655hahhahhahahahha\n",
      "\n",
      "Epoch: 10/10... Step: 6550... Loss: 0.706915... Val Loss: 0.540743\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "validLoss,trainLoss = [],[]\n",
    "epochs = 10 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "minValidLoss = np.inf #use for saving model whenever valid loss becomes less than min valid loss\n",
    "\n",
    "# move model to GPU, if available\n",
    "device = 'cuda' if(torch.cuda.is_available()) else 'cpu'\n",
    "net.to(device)\n",
    "print(\"Running on\",device)\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    print(\"e:\",e)\n",
    "    h = net.init_hidden(batch_size)\n",
    "    print(h[0].shape)\n",
    "    # batch loop\n",
    "    print()\n",
    "    for batch,(inputs, labels) in enumerate(train_loader,1):\n",
    "        print(f'\\rBatch : {batch}/{len(train_loader)}',end='')\n",
    "        counter += 1\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda().long(), labels.cuda().long()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "        \n",
    "#         htemp = tuple([each.data for each in h])\n",
    "#         print(inputs[2].shape)\n",
    "#         print(\"======================\")\n",
    "#         print(h[1].shape)\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "#         print(h[1].shape)\n",
    "        \n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "#         print(\"ok\")\n",
    "\n",
    "        # loss stats\n",
    "    else:\n",
    "        # Get validation loss\n",
    "        print(\"hahhahhahahahha\")\n",
    "        print()\n",
    "        val_h = net.init_hidden(batch_size)\n",
    "        val_losses = []\n",
    "        net.eval()\n",
    "        for inputs, labels in valid_loader:\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            if(train_on_gpu):\n",
    "                inputs, labels = inputs.cuda().long(), labels.cuda().long()\n",
    "\n",
    "            output, val_h = net(inputs, val_h)\n",
    "            val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "        net.train()\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Step: {}...\".format(counter),\n",
    "              \"Loss: {:.6f}...\".format(loss.item()),\n",
    "              \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "        \n",
    "        if(np.mean(val_losses)<minValidLoss):\n",
    "          print('\\t\\t...Saving Model...')\n",
    "          torch.save(net.state_dict(),'LSTM_Model.pt')\n",
    "          minValidLoss = np.mean(val_losses)\n",
    "          \n",
    "        trainLoss.append(loss.item())\n",
    "        validLoss.append(np.mean(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trainLoss,color='g')\n",
    "plt.plot(validLoss,color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.445\n",
      "Test accuracy: 0.392\n"
     ]
    }
   ],
   "source": [
    "#Loading saved model\n",
    "net.load_state_dict(torch.load('LSTM_Model.pt'))\n",
    "\n",
    "if(train_on_gpu):\n",
    "  net.to('cuda')\n",
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda().long(), labels.cuda().long()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loading saved model\n",
    "net.load_state_dict(torch.load('LSTM_Model.pt'))\n",
    "\n",
    "if(train_on_gpu):\n",
    "  net.to('cuda')\n",
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda().long(), labels.cuda().long()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36854, 25)\n",
      "torch.Size([36854, 25])\n",
      "torch.Size([4095, 1, 1])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-250-63c3ce0c33a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_tensor_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_tensor_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_tensor_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_tensor_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create your datset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create your dataloader if you get a error when loading test data you can set a batch_size here as well like train_dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "import torch.utils.data as utils\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn=torch.nn.LSTM(\n",
    "            input_size=25,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out=torch.nn.Linear(in_features=64,out_features=3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # 一下关于shape的注释只针对单项\n",
    "        # output: [batch_size, time_step, hidden_size]\n",
    "        # h_n: [num_layers,batch_size, hidden_size] # 虽然LSTM的batch_first为True,但是h_n/c_n的第一维还是num_layers\n",
    "        # c_n: 同h_n\n",
    "        output,(h_n,c_n)=self.rnn(x)\n",
    "        print(output.size())\n",
    "        # output_in_last_timestep=output[:,-1,:] # 也是可以的\n",
    "        output_in_last_timestep=h_n[-1,:,:]\n",
    "        # print(output_in_last_timestep.equal(output[:,-1,:])) #ture\n",
    "        x=self.out(output_in_last_timestep)\n",
    "        return x\n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # print(\"shape:\",output.shape)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0: #Print loss every 100 batch\n",
    "            print('Train Epoch: {}\\tLoss: {:.6f}'.format(\n",
    "                epoch, loss.item()))\n",
    "    accuracy = test(model, device, train_loader)\n",
    "    return accuracy    \n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return accuracy\n",
    "\n",
    "# #Dimensions of output of neural network is (seq_len, batch , hidden_dim). Since we want output dimensions to be\n",
    "# #the same as n_letters, hidden_dim = n_letters (output dimensions = hidden_dimensions)\n",
    "# hidden_dim = n_letters     \n",
    "# #Invoking model. Input dimensions = n_letters i.e 28. output dimensions = hidden_dimensions = 28\n",
    "# model = MyLSTM(n_letters,hidden_dim)\n",
    "# #I'm using Adam optimizer here\n",
    "# optimizer = torch.optim.Adam(params = model.parameters(),lr=0.01)\n",
    "# #Loss function is CrossEntropyLoss\n",
    "# LOSS = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# #List to store targets\n",
    "# targets = []\n",
    "# #Iterate through all chars in the sequence, starting from second letter. Since output for 1st letter is the 2nd letter\n",
    "# for x in data[1:]+'#':\n",
    "#     #Find the target index. For a, it is 0, For 'b' it is 1 etc..\n",
    "#     targets.append(letters.find(x))\n",
    "# #Convert into tensor\n",
    "# targets = torch.tensor(targets)\n",
    "\n",
    "# #List to store input\n",
    "# inpl = []\n",
    "# #Iterate through all inputs in the sequence\n",
    "# for c in data:\n",
    "#     #Convert into tensor\n",
    "#     inpl.append(ltt(c))\n",
    "# #Convert list to tensor\n",
    "# inp = torch.cat(inpl,dim=0)\n",
    "# #Reshape tensor into 3 dimensions (sequence length, batches = 1, dimensions = n_letters (28))\n",
    "# inp = inp.view(seq_len,1,n_letters)\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "# Training settings\n",
    "use_cuda = True # Switch to False if you only want to use your CPU\n",
    "learning_rate = 0.01\n",
    "NumEpochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "device = \"cpu\"#torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_X = train_data_features\n",
    "# train_Y = train_Y.values\n",
    "test_X = test_data_features\n",
    "# test_Y = test_Y.values\n",
    "\n",
    "train_X = X_train_word_average.reshape([-1,25])#train_X.reshape([1,1,3000]) # the data is flatten so we reshape it here to get to the original dimensions of images\n",
    "test_X = X_train_word_average.reshape([-1,25])#test_X.reshape([1,1,3000])\n",
    "print(train_X.shape)\n",
    "# transform to torch tensors\n",
    "tensor_x = torch.tensor(train_X, device=device)#.todense()\n",
    "tensor_y = torch.tensor(train_Y, dtype=torch.long, device=device)\n",
    "\n",
    "test_tensor_x = torch.tensor(test_X, device=device)\n",
    "test_tensor_y = torch.tensor(test_Y, dtype=torch.long)\n",
    "\n",
    "train_dataset = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "train_loader = utils.DataLoader(train_dataset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "print(test_tensor_x.shape)\n",
    "print(test_tensor_y.shape)\n",
    "test_dataset = utils.TensorDataset(test_tensor_x,test_tensor_y) # create your datset\n",
    "\n",
    "test_loader = utils.DataLoader(test_dataset) # create your dataloader if you get a error when loading test data you can set a batch_size here as well like train_dataloader\n",
    "\n",
    "model = RNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "trainHis = []\n",
    "testHis = []\n",
    "# summary(model, (3000,1))\n",
    "for epoch in range(NumEpochs):\n",
    "    train_acc = train(model, device, train_loader, optimizer, epoch)\n",
    "    print('\\nTrain set Accuracy: {:.0f}%\\n'.format(train_acc))\n",
    "    test_acc = test(model, device, test_loader)\n",
    "    print('\\nTest set Accuracy: {:.0f}%\\n'.format(test_acc))\n",
    "    trainHis.append(train_acc)\n",
    "    testHis.append(test_acc)\n",
    "torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "#TODO: Plot train and test accuracy vs epoch\n",
    "plt.plot( range(NumEpochs), trainHis, label=\"train\")\n",
    "# plt.plot( epochs, acc_his['val'], label=\"validation\")\n",
    "plt.plot( range(NumEpochs), testHis, label=\"test\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 70, got 25",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-316-03d83bdf4c8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# 前向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m#     print(\"here4\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;31m#     print(\"here3\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-316-03d83bdf4c8c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    147\u001b[0m             raise RuntimeError(\n\u001b[0;32m    148\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m--> 149\u001b[1;33m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 70, got 25"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data_csv = pd.read_csv('./data.csv',usecols=[1])\n",
    "# plt.plot(data_csv)\n",
    "\n",
    "# 数据预处理\n",
    "# data_csv = data_csv.dropna()  # 滤除缺失数据\n",
    "# dataset = data_csv.values   # 获得csv的值\n",
    "# dataset = dataset.astype('float32')\n",
    "# max_value = np.max(dataset)  # 获得最大值\n",
    "# min_value = np.min(dataset)  # 获得最小值\n",
    "# scalar = max_value - min_value  # 获得间隔数量\n",
    "# dataset = list(map(lambda x: x / scalar, dataset)) # 归一化\n",
    "\n",
    "# def create_dataset(dataset, look_back=2):\n",
    "#     dataX, dataY = [], []\n",
    "#     for i in range(len(dataset) - look_back):\n",
    "#         a = dataset[i:(i + look_back)]\n",
    "#         dataX.append(a)\n",
    "#         dataY.append(dataset[i + look_back])\n",
    "#     return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 创建好输入输出\n",
    "# data_X, data_Y = create_dataset(dataset)\n",
    "\n",
    "# 划分训练集和测试集，70% 作为训练集\n",
    "# train_size = int(len(data_X) * 0.7)\n",
    "# test_size = len(data_X) - train_size\n",
    "# train_X = data_X[:train_size]\n",
    "# train_Y = data_Y[:train_size]\n",
    "# test_X = data_X[train_size:]\n",
    "# test_Y = data_Y[train_size:]\n",
    "\n",
    "import torch\n",
    "\n",
    "train_y, test_y = train_test_split(y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "train_X = np.array(X_train_word).reshape(70, -1, 25)\n",
    "train_Y = train_y.reshape(-1, 1, 1)\n",
    "test_X = np.array(X_test_word).reshape(70, -1, 25)\n",
    "test_Y = test_y.reshape(-1, 1, 1)\n",
    "\n",
    "train_x = torch.from_numpy(train_X)\n",
    "train_y = torch.from_numpy(train_Y)\n",
    "test_x = torch.from_numpy(test_X)\n",
    "test_y = torch.from_numpy(test_Y)\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self,input_size=25,hidden_size=50,output_size=3,num_layer=2):\n",
    "        super(lstm,self).__init__()\n",
    "        self.layer1 = nn.LSTM(input_size,hidden_size,num_layer)\n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x,_ = self.layer1(x.float())\n",
    "        s,b,h = x.size()\n",
    "        x = x.view(s*b,h)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(s,b,-1)\n",
    "        return x\n",
    "\n",
    "model = lstm(70, 50,1,2)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "data_X = np.array(test_X).reshape(70, -1, 25)\n",
    "data_X = torch.from_numpy(data_X)\n",
    "var_data = Variable(data_X)\n",
    "\n",
    "# 开始训练\n",
    "\n",
    "for e in range(1):\n",
    "    model.train()\n",
    "    var_x = Variable(train_x)\n",
    "    var_y = Variable(train_y.float())\n",
    "    # 前向传播\n",
    "#     print(\"here4\")\n",
    "    out = model(var_x)\n",
    "#     print(\"here3\")\n",
    "    loss = criterion(out, var_y)\n",
    "    # 反向传播\n",
    "#     print(\"here2\")\n",
    "    optimizer.zero_grad()\n",
    "#     print(\"here1\")\n",
    "    loss.backward()\n",
    "#     print(\"here\")\n",
    "    optimizer.step()\n",
    "    print(\"loss:\",loss.item())\n",
    "#     if (e + 1) % 10 == 0: # 每 100 次输出结果\n",
    "#         print('Epoch: {}, Loss: {:.5f}'.format(e+1, loss.item()))\n",
    "\n",
    "model = model.eval() # 转换成测试模式\n",
    "\n",
    "pred_test = model(var_data) # 测试集的预测结果\n",
    "# 改变输出的格式\n",
    "pred_test = pred_test.view(-1).data.numpy()\n",
    "\n",
    "# 画出实际结果和预测的结果\n",
    "# plt.plot(pred_test, 'r', label='prediction')\n",
    "# plt.plot(test_y, 'b', label='real')\n",
    "# plt.legend(loc='best')\n",
    "# pred_test.dtype=\"int32\"\n",
    "\n",
    "print(np.sum(np.floor(pred_test.reshape(-1))==test_Y.reshape(-1))/4095)\n",
    "print(np.sum(np.ceil(pred_test.reshape(-1))==test_Y.reshape(-1))/4095)\n",
    "print(np.sum(np.rint(pred_test.reshape(-1))==test_Y.reshape(-1))/4095)\n",
    "\n",
    "# print(pred_test)\n",
    "# print(\"=============================\")\n",
    "# print(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
